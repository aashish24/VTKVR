\subsection{Approach}
The new vtkGPUVolumeRayCastMapper uses a ray casting technique ~\ref{raycasting} for volume rendering which is a state-of-the-art for volume rendering on modern graphics platforms. Algorithmically, at a high level, it is similar to the older version of this class (although with a fairly different OpenGL implementation since that original class was first written over a decade ago and used GPU assembly code).  One of the main reason we chose to use ray casting due to the flexibility of this technique, which enables us to support all the features of the software ray cast mapper but with the acceleration of the GPU. Ray casting is an image-order rendering technique, with one or more rays cast through the volume per image pixel. VTK is inherently an object-order rendering system, where the GPU renders all graphical primitives (points, lines, triangles, etc.) represented by vtkProp(s) in the scene in one or more passes (with multiple passes needed to support advanced features such as depth peeling for transparency).

The image-order rendering process for vtkVolume is initiated when the front-facing polygons of the volumeâ€™s bounding box are rendered with a custom fragment program. This fragment program is used to cast a ray through the volume at each pixel, with the fragment location indicating the starting location for that ray. The volume and all the various rendering parameters are transferred to the GPU through the use of textures (3D for the volume, 1D for the various transfer functions) and uniform variables. Steps are taken along the ray until the ray exits the volume, and the resulting computed color and opacity are blended into the current pixel value. Note that volumes are rendered after all opaque geometry in the scene to allow the ray casting process to terminate at the depth value stored in the depth buffer for that pixel (and, hence, correctly intermix with opaque geometry).

In addition to providing supported features of the old mapper, the new mapper added new capabilities such as clipping on GPU,  gradient opacity, and volume picking amongst many others. In the next few sections, we will cover each of these features in detail.

\subsubsection{Single Pass}
\begin{figure}
\centering
\includegraphics[width=3in]{frontandback.png}
\caption{Front and back faces are rendered for start and end position of the ray.}
\label{fig:raycasting}
\end{figure}


\begin{figure}
\centering
\includegraphics[width=3in]{raycasting.jpg}
\caption{Implementing volume rendering using single-pass GPU ray casting.}
\label{fig:raycasting}
\end{figure}

In a ray-casting algorithm, the entry and the exit point into the volume is needed to determine when to stop the ray-marching. To determine the entry and the exit point, one approach is to render the geometry of the volume bounding box of the volume twice. In the first pass, the front face of the geometry is rendered and in the second pass the backface is rendered as shown in ~\ref{fig:frontandback}. Using the interpolated vertex position and texture lookup, the start and end positions is computed. Instead of this, in vtkGPUVolumeRayCastMapper, entry and exit points are computed based on the fact that the texture extents of the volume is within vec3(1.0), vec3(-1.0) range (and ~\ref{fig:raycasting}). The code below is showing the fragment shader piece that determines whether or not to stop marching the rays depending on the value of stop.
 
 \begin{lstlisting}[breaklines=true]
 bool stop = any(greaterThan(g_dataPos, 
                 ip_texMax)) ||
             any(lessThan(g_dataPos, 
                 ip_texMin));
 \end{lstlisting}
 
 The advantage of such approach is that it requires one less pass and is faster than other approaches since there is no texture generation or lookup happens for determining the termination of the ray.
 
 
 \subsubsection{Dynamic Shader Generation}
 In the new \texttt{vtkOpenGLGPUVolumeRayCastMapper} all the operations are performed on the GPU. The advantage of this approach was a more streamlined code that is easier to maintain and debug. This approach also provided an opportunity to rework how to support different features without having too many branches in the shader code or having to send all the options to the shader because that would have been detrimental to the performance. In the new \texttt{vtkOpenGLGPUVolumeRayCastMapper}, the shader is dynamically composed by the mapper. For this to work, we have introduced tags in a vertex, or fragment shader which are then replaced by the \texttt{vtkShaderComposer} depending on the option enabled or chosen by the application code. For instance, the skeleton fragment shader defines tags as shown below:
 
 \begin{lstlisting}
//VTK::Base::Dec

//VTK::Termination::Dec 
\end{lstlisting}

At the run time then \texttt{//VTK::Base::Dec} is then replaced by the code shown below. 

To define a structure, we have chosen a strategy that separates the tags in found category: 

1. Declaration (:: Dec)
The tags belong to this group are meant to declare variables or function outside the main execution of the shader code. The variables defined are uniform, varying, and user-defined global variables. The functions defined are typically perform operations that are repetitive in nature such as computing color of a fragment. 

2. Initialization (:: Init)
The tags belong to this group are meant to initialize variables inside the main execution function of the shader but before the ray-casting loop in the fragment shader. An example of such code includes computation of the initial position of ray and direction of ray traversal.

3. Implementation (::Impl)
The tags belong to this group are the variables or functions or the combination of both that perform the actual operation of clipping, cropping, shading, etc. on one, two, or four component volume data. The implementation code used local and global variables and optimized for performance reasons as they are executed as long as the ray is traversing inside the volume and didn't run into a termination condition which is checked every time.  

4. Exit (:: Exit)
The tags belong to this group perform final computation such as the final color of the fragment. These tags are placed outside the ray-casting loop and typically contain numeric assignments.

\subsubsection{Optimizations and Handling of Edge-Cases}
The new \texttt{vtkOpenGLGPUVolumeRayCastMapper} is more than just a ray cast mapper implementation. It is designed to work on multiple platforms and developed to perform volume rendering at interactive frame rates. To achieve interactive frame rates and to handle edge cases, we have implemented following optimizations in the new mapper. 

\begin{itemize}
\item Clipping plane optimization 
In VTK a user can place multiple planes at desired angles to clip the volume. This technique is essential for many medical use-cases. Since only one side of clip planes needs to be traversed, performing any sort of ray cast on the clipped side is wasteful. Hence a simple optimization is to move the starting point of the ray on the plane by projecting the ray onto the plane in the view direction. 

\item Eye Too Close to the Volume

\item Volume Texture Streaming



\end{itemize}

\subsubsection{Cropping}
Cropping refers to 27 regions that defined by two planes along each coordinate axis of the volume and can be independently turned on (visible) or off (invisible) to produce a variety of different cropping effects, as shown in Figure~\ref{fig:cropping}. Cropping is implemented by determining the cropping region of each sample location along the ray and including only those samples that fall within a visible region.

\begin{figure}
\centering
\includegraphics[width=2.5in]{SphereCropping.png}
\caption{Figure 3. A sphere is cropped using two different configurations of cropping regions.}
\label{fig:cropping}
\end{figure}

\subsubsection{Wide Support of Data Types} 
The vtkGPURayCastMapper supports most data types such as short, int, float, and double and both point and cell data types. Bias are scale are computed and applied to the scalars in the fragment shader to normalize the scalars between 0-1 range. 

\subsubsection{Clipping}
A set of infinite clipping planes can be defined to clip the volume to reveal inner detail, as shown in Figure 4.  Clipping is implemented by determining the visibility of each sample along the ray according to whether that location is excluded by the clipping planes.A set of infinite clipping planes can be defined to clip the volume to reveal inner detail, as shown in Figure 4.  Clipping is implemented by determining the visibility of each sample along the ray according to whether that location is excluded by the clipping planes.

\begin{figure}
\centering
\includegraphics[width=2.5in]{HeadClippingOblique.png}
\caption{Figure 4. Top: An example of an oblique clipping plane. Bottom: A pair of parallel clipping planes clip the volume, rendered without (left) and with (right) shading.}
\label{fig:clipping}
\end{figure}

\subsubsection{Blending Modes}
The mapper supports composite blending, minimum intensity projection, maximum intensity projection, and additive blending. Each of these blending modes are useful for a particular use-case in medical computing. The most common one which is also the default is the composite blending mode. See Figure~\ref{fig:blendingmodes} for an example of composite blending, maximum intensity projection, and additive blending on the same data.

\begin{figure*}
\centering
\begin{subfigure}{.6\columnwidth}
    \includegraphics[width=\columnwidth]{TorsoBlendingComposite.png}
\end{subfigure}
\begin{subfigure}{.6\columnwidth}   
    \includegraphics[width=\columnwidth]{TorsoBlendingAdditive.png}
\end{subfigure} 
\begin{subfigure}{.6\columnwidth}
    \includegraphics[width=\columnwidth]{TorsoBlendingMIP.png}
\end{subfigure}
\caption{Rendering with and without gradient opacity transfer function.}
\label{fig:blendingmodes}
\end{figure*}

\subsubsection{Masking}
Both binary and label masks are supported. With binary masks, the value in the masking volume indicates visibility of the voxel in the data volume. When a label map is in use, the value in the label map is used to select different rendering parameters for that sample.  See Figure 5 for an example of label data masks.

\subsubsection{Opacity Modulated by Gradient Magnitude}
A transfer function mapping the magnitude of the gradient to an opacity modulation value can be used to essentially perform edge detection (de-emphasize homogenous regions) during rendering. See ~\ref{fig:gradient} for an example of rendering with and without the use of a gradient opacity transfer function.

\begin{figure*}
\centering
   \begin{subfigure}[b]{0.5\textwidth}
   \includegraphics[width=1\linewidth]{TorsoGradient.png}
   \caption{}
   \label{fig:Ng1} 
\end{subfigure}

\begin{subfigure}[b]{0.5\textwidth}
   \includegraphics[width=1\linewidth]{TorsoNoGradient.png}
   \caption{}
   \label{fig:Ng2}
\end{subfigure}

\caption{Rendering with and without gradient opacity transfer function.}
\label{fig:gradient}
\end{figure*}

\subsubsection{Mobile Support}
The move to OpenGL 3 and higher enabled volume rendering to support mobile devices (iOS and Android devices) as OpenGL ES 3.0 and higher supports 3D textures. Support for multiple touch events such as using two fingers to translate, rotate, and zoom the camera was added to support interactive rendering on mobile devices. New texture formats are added with logistics to enable / disable them based on the platform.. With minor feature-set exceptions, the new volume mapper works on mobile devices enabling developers to build sophisticated applications for the scientific community.

\subsubsection{Volume Picking}
Picking is defined in this context as the effort of determining which on-screen object a user has clicked on,  this is one of the most basic operations to interact with a 3D scene. VTK legacy volume mappers support picking through an instance external to the mapper itself called vtkVolumePicker.  This class casts a ray into the volume and returns the point where the ray intersects an isosurface of a user specified opacity. This technique has certain limitations given that the picking class does not have enough information to correctly account for clipping, transfer functions and other parameters which define how the mapper renders internally, this reduces its reliability on the actual objects being picked.
The inherent flexibility of the glsl-based implementation of the new vtkGPURayCastMapper enables seamless integration with the vtkHardwareSelector's interface, which allows a consistent selection of objects in a scene regardless of whether it is geometric or volumetric data.  Providing picking support directly within the fragment shader of the volume mapper ensures high selection accuracy even in situations where a volume intermixes with geometry in seemingly cumbersome ways or advanced features like when clipping planes are enabled (what you see is what you pick).
Furthermore, this initial implementation supports a higher picking granularity than only the volume object itself (vtkProp).  Given the readily available picking styles supported by vtkHardwareSelector (e.g. vtkAreaPicker), it is possible to make a selection of a specific set of voxels.

\subsubsection{Lighting / Shading }
The old GPU ray cast mapper supported only one light (due to limitations in OpenGL at the time the class was written). The vtkFixedPointRayCastMapper supports multiple lights, but only with an approximate lighting model, since gradients are precomputed and quantized, and shading is performed for each potential gradient direction regardless of fragment location. The new vtkGPURayCastMapper accurately implemented the VTK lighting model to produce high quality images for publication. Up To six lights are supported (point, directional, and positional). The number of lights are limited to six mostly because of the performance reasons as the interactive performance goes down significantly with each light added to the scene. 

\subsubsection{Volume Texture Streaming}
An intrinsic limitation of volume rendering is that the texture to be rendered does not always fit into the graphics memory of a system. This becomes increasingly important to address now that the new mapper provides support for mobile architectures.
A relatively simple method when dealing with a large volume is the divide-and-conquer approach, which is sometimes referred to as bricking. The volume is split into several blocks in such a way that a single sub-block (brick) fits completely into GPU memory.  Each sub-block is stored in main memory and streamed into GPU memory for a rendering pass one at a time (in a back-to-front manner for correct composition). The sub-blocks are rendered using the standard shader programs and alpha-blended with each other by OpenGL.
Streaming the volume as separate texture bricks certainly imposes a performance trade-off but acts as a graphics memory expansion scheme for devices that would not be able to render a higher quality volume otherwise.

\subsubsection{Dual Depth Peeling}
 
 
 
 