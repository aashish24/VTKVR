
@book{schroeder_visualization_2006,
  edition = {4th},
  title = {The {{Visualization Toolkit}} - {{An Object}}-{{Oriented Approach}} to {{3D Graphics}}},
  isbn = {978-1-930934-19-1},
  language = {en},
  timestamp = {2017-04-28T14:30:42Z},
  urldate = {2017-03-09},
  publisher = {{Kitware, Inc.}},
  author = {Schroeder, Will and Martin, Ken and Bill, Lorensen},
  year = {2006}
}

@book{ahrens_paraview:_2005,
  title = {{{ParaView}}: {{An End}}-{{User Tool}} for {{Large Data Visualization}}},
  isbn = {978-0-12-387582-2},
  timestamp = {2017-03-09T18:38:24Z},
  publisher = {{Visualization Handbook, Elsevier}},
  author = {Ahrens, James and Geveci, Berk and Law, Charles},
  year = {2005}
}

@book{ayachit_paraview_2015,
  title = {The {{ParaView Guide}}: {{A Parallel Visualization Application}}},
  isbn = {978-1-930934-30-6},
  timestamp = {2017-03-09T18:40:02Z},
  publisher = {{Kitware, Inc.}},
  author = {Ayachit, Utkarsh},
  year = {2015}
}

@techreport{bavoil_order_2008,
  title = {Order {{Independent Transparency}} with {{Dual Depth Peeling}}},
  timestamp = {2017-03-09T18:47:05Z},
  institution = {NVIDIA},
  author = {Bavoil, Louis and Myers, Kevin},
  year = {2008}
}

@inproceedings{ayachit_paraview_2015-1,
  address = {New York, NY, USA},
  series = {ISAV2015},
  title = {{{ParaView Catalyst}}: {{Enabling In Situ Data Analysis}} and {{Visualization}}},
  isbn = {978-1-4503-4003-8},
  shorttitle = {{{ParaView Catalyst}}},
  doi = {10.1145/2828612.2828624},
  abstract = {Computer simulations are growing in sophistication and producing results of ever greater fidelity. This trend has been enabled by advances in numerical methods and increasing computing power. Yet these advances come with several costs including massive increases in data size, difficulties examining output data, challenges in configuring simulation runs, and difficulty debugging running codes. Interactive visualization tools, like ParaView, have been used for post-processing of simulation results. However, the increasing data sizes, and limited storage and bandwidth make high fidelity post-processing impractical. In situ analysis is recognized as one of the ways to address these challenges. In situ analysis moves some of the post-processing tasks in line with the simulation code thus short circuiting the need to communicate the data between the simulation and analysis via storage. ParaView Catalyst is a data processing and visualization library that enables in situ analysis and visualization. Built on and designed to interoperate with the standard visualization toolkit VTK and the ParaView application, Catalyst enables simulations to intelligently perform analysis, generate relevant output data, and visualize results concurrent with a running simulation. In this paper, we provide an overview of the Catalyst framework and some of the success stories.},
  timestamp = {2017-03-09T18:49:32Z},
  urldate = {2017-03-09},
  booktitle = {Proceedings of the {{First Workshop}} on {{In Situ Infrastructures}} for {{Enabling Extreme}}-{{Scale Analysis}} and {{Visualization}}},
  publisher = {{ACM}},
  author = {Ayachit, Utkarsh and Bauer, Andrew and Geveci, Berk and O'Leary, Patrick and Moreland, Kenneth and Fabian, Nathan and Mauldin, Jeffrey},
  year = {2015},
  pages = {25--29}
}

@book{weiskopf_gpu-based_2006,
  address = {New York, NY, USA},
  title = {{{GPU}}-{{Based Interactive Visualization Techniques}}},
  isbn = {978-3-540-33262-6},
  abstract = {Scientific visualization has become an important tool for visual analysis in many scientific, engineering, and medical disciplines.
This book focuses on...},
  timestamp = {2017-03-09T18:54:14Z},
  urldate = {2017-03-09},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Weiskopf, Daniel},
  year = {2006},
  file = {Snapshot:/Users/sankheshjhaveri/Library/Application Support/Zotero/Profiles/4gdw0u3h.default/zotero/storage/B5WXU7UQ/9783540332626.html:text/html}
}

@misc{hanwell_tomviz_2014,
  title = {Tomviz for Tomographic Visualization of Nanoscale Materials},
  language = {en},
  timestamp = {2017-05-11T17:02:38Z},
  urldate = {2017-03-09},
  howpublished = {\url{http://www.tomviz.org/}},
  journal = {tomviz},
  author = {Hanwell, Marcus D. and Ayachit, Utkarsh and Muller, David and Hovden, Robert},
  year = {2014},
  file = {Snapshot:/Users/sankheshjhaveri/Library/Application Support/Zotero/Profiles/4gdw0u3h.default/zotero/storage/35WIESPF/www.tomviz.org.html:text/html}
}

@misc{visfiles_visfiles_2007,
  title = {{{VisFiles}}},
  timestamp = {2017-03-27T19:12:08Z},
  urldate = {2017-03-15},
  howpublished = {\url{http://vis.cs.ucdavis.edu/VisFiles/index.php}},
  journal = {VisFiles},
  author = {{VisFiles}},
  year = {2007}
}

@article{hiroshi_akiba_visualizing_2007,
  title = {Visualizing Multivariate Volume Data from Turbulent Combustion Simulations},
  volume = {9},
  doi = {10.1109/MCSE.2007.42},
  abstract = {To understand dynamic mechanisms, scientists need intuitive and convenient ways to validate known relationships and reveal hidden ones among multiple variables.},
  timestamp = {2017-03-15T19:21:30Z},
  journal = {Computing in Science \& Engineering},
  author = {{Hiroshi Akiba} and {Evatt R. Hawkes} and {Kwan-Liu Ma} and {Jacqueline H. Chen}},
  year = {March/April 2007},
  pages = {76--83}
}

@misc{osirix_osirix_2017,
  title = {{{OsiriX}} | {{DICOM Image Library}}},
  timestamp = {2017-03-27T19:12:01Z},
  urldate = {2017-03-15},
  howpublished = {\url{http://www.osirix-viewer.com/resources/dicom-image-library/}},
  journal = {OsiriX | DICOM Image Library},
  author = {{OsiriX}},
  year = {2017},
  file = {OsiriX | DICOM Image Library:/Users/sankheshjhaveri/Library/Application Support/Zotero/Profiles/4gdw0u3h.default/zotero/storage/3EHI29RF/dicom-image-library.html:text/html}
}

@article{hanwell_visualization_2015,
  title = {The {{Visualization Toolkit}} ({{VTK}}): {{Rewriting}} the Rendering Code for Modern Graphics Cards},
  volume = {1\textendash{}2},
  issn = {2352-7110},
  shorttitle = {The {{Visualization Toolkit}} ({{VTK}})},
  doi = {10.1016/j.softx.2015.04.001},
  abstract = {The Visualization Toolkit (VTK) is an open source, permissively licensed, cross-platform toolkit for scientific data processing, visualization, and data analysis. It is over two decades old, originally developed for a very different graphics card architecture. Modern graphics cards feature fully programmable, highly parallelized architectures with large core counts. VTK's rendering code was rewritten to take advantage of modern graphics cards, maintaining most of the toolkit's programming interfaces. This offers the opportunity to compare the performance of old and new rendering code on the same systems/cards. Significant improvements in rendering speeds and memory footprints mean that scientific data can be visualized in greater detail than ever before. The widespread use of VTK means that these improvements will reap significant benefits.},
  timestamp = {2017-04-13T04:28:07Z},
  urldate = {2017-04-13},
  journal = {SoftwareX},
  author = {Hanwell, Marcus D. and Martin, Kenneth M. and Chaudhary, Aashish and Avila, Lisa S.},
  month = sep,
  year = {2015},
  keywords = {Data analysis,Scientific data,Toolkit,Visualization},
  pages = {9--12},
  file = {ScienceDirect Snapshot:/Users/sankheshjhaveri/Library/Application Support/Zotero/Profiles/4gdw0u3h.default/zotero/storage/4JSA9ZZ8/Hanwell et al. - 2015 - The Visualization Toolkit (VTK) Rewriting the ren.html:text/html}
}

@article{scott_electron_2012,
  title = {Electron Tomography at 2.4-Angstrom Resolution},
  volume = {483},
  copyright = {\textcopyright{} 2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  issn = {0028-0836},
  doi = {10.1038/nature10934},
  abstract = {Transmission electron microscopy is a powerful imaging tool that has found broad application in materials science, nanoscience and biology. With the introduction of aberration-corrected electron lenses, both the spatial resolution and the image quality in transmission electron microscopy have been significantly improved and resolution below 0.5\,angstroms has been demonstrated. To reveal the three-dimensional (3D) structure of thin samples, electron tomography is the method of choice, with cubic-nanometre resolution currently achievable. Discrete tomography has recently been used to generate a 3D atomic reconstruction of a silver nanoparticle two to three nanometres in diameter, but this statistical method assumes prior knowledge of the particle/'s lattice structure and requires that the atoms fit rigidly on that lattice. Here we report the experimental demonstration of a general electron tomography method that achieves atomic-scale resolution without initial assumptions about the sample structure. By combining a novel projection alignment and tomographic reconstruction method with scanning transmission electron microscopy, we have determined the 3D structure of an approximately ten-nanometre gold nanoparticle at 2.4-angstrom resolution. Although we cannot definitively locate all of the atoms inside the nanoparticle, individual atoms are observed in some regions of the particle and several grains are identified in three dimensions. The 3D surface morphology and internal lattice structure revealed are consistent with a distorted icosahedral multiply twinned particle. We anticipate that this general method can be applied not only to determine the 3D structure of nanomaterials at atomic-scale resolution, but also to improve the spatial resolution and image quality in other tomography fields.},
  language = {en},
  timestamp = {2017-04-13T04:30:04Z},
  number = {7390},
  urldate = {2017-04-13},
  journal = {Nature},
  author = {Scott, M. C. and Chen, Chien-Chun and Mecklenburg, Matthew and Zhu, Chun and Xu, Rui and Ercius, Peter and Dahmen, Ulrich and Regan, B. C. and Miao, Jianwei},
  month = mar,
  year = {2012},
  keywords = {Applied physics,Engineering,Materials science,Physics},
  pages = {444--447},
  file = {Snapshot:/Users/sankheshjhaveri/Library/Application Support/Zotero/Profiles/4gdw0u3h.default/zotero/storage/S4JRF6AW/nature10934.html:text/html}
}

@article{miao_atomic_2016,
  title = {Atomic Electron Tomography: {{3D}} Structures without Crystals},
  volume = {353},
  copyright = {Copyright \textcopyright{} 2016, American Association for the Advancement of Science},
  issn = {0036-8075, 1095-9203},
  shorttitle = {Atomic Electron Tomography},
  doi = {10.1126/science.aaf2157},
  abstract = {Structured Abstract
BACKGROUNDTo understand material properties and functionality at the most fundamental level, one must know the three-dimensional (3D) positions of atoms with high precision. For crystalline materials, x-ray crystallography has provided this information since the pioneering work of Max von Laue, William Henry Bragg, and William Lawrence Bragg around 100 years ago. But perfect crystals are rare in nature. Real materials often contain defects, surface reconstructions, nanoscale heterogeneities, and disorders, which strongly influence material properties and performance. Completely different approaches from crystallography are needed to determine the 3D atomic arrangement of crystal defects and noncrystalline systems. Although single-particle cryo\textendash{}electron microscopy (cryo-EM) has been under rapid development for 3D structure determination of macromolecules with identical or similar conformations at near-atomic resolution, this method cannot be generally applied to the physical sciences for the following three reasons. First, most materials do not have identical copies and cannot be averaged to achieve atomic resolution. Second, a priori knowledge of the peptide sequence and stereochemistry in protein molecules greatly facilitates their 3D atomic structure determination, but this knowledge is not applicable to physical science samples. Third, unlike in biological specimens, the presence of diffraction and phase contrast in the transmission electron microscopy images of most materials poses a challenge for tomographic reconstruction.These difficulties have made the objective of solving the 3D atomic structure of crystal defects and noncrystalline systems a major challenge for structural characterization in the physical sciences.
ADVANCESMajor developments in aberration-corrected electron microscopes, advanced detectors, data acquisition methods, powerful 3D image reconstruction, and atom-tracing algorithms have placed one method\textemdash{}atomic electron tomography (AET)\textemdash{}on the cusp of this breakthrough. In recent years, AET has been used to image the 3D structure of grain boundaries and stacking faults and the 3D core structure of edge and screw dislocations at atomic resolution. This technique has also revealed the existence of atomic steps at 3D twin boundaries that are hidden in conventional 2D projections. Furthermore, the combination of AET and atom-tracing algorithms has enabled the determination of the coordinates of individual atoms and point defects in materials with a 3D precision of \textasciitilde{}19 pm, allowing direct measurements of 3D atomic displacements and the full strain tensor. Finally, the single-particle reconstruction method developed in cryo-EM has been applied for 3D structure determination of small ($\leq$2-nm) gold nanoparticles and heterogeneous platinum nanocrystals at atomic-scale resolution.
OUTLOOKThe future research frontiers of AET involve increasing the sample complexity (including real materials with different atomic species and disordered systems), image contrast (determining the 3D atomic positions of both heavy and light elements), detection sensitivity (revealing individual atoms at surfaces and interfaces), and data acquisition speed (probing the dynamics of individual atoms and defects). The ability to precisely determine all atomic coordinates and species in real materials without assuming crystallinity will transform our understanding of structure-property relationships at the most fundamental level. For instance, using atomic coordinates as inputs to first-principles calculations, it is possible to compute the effect on the material properties of each defect and atomic reorganization, giving precious clues about how to modify and engineer materials at the atomic level to yield better performance in a device. Catalysis involves atoms interacting on nanoparticle surfaces in poorly understood ways, and the mechanisms of particle growth in synthesis reactors or in devices under load are largely unknown. Breakthroughs in our ability to reliably measure this information in 3D will have effects across disciplines from electronics and catalysis to energy conversion. $<$img class="fragment-image" src="https://d2ufo47lrtsv5s.cloudfront.net/content/sci/353/6306/aaf2157/F1.medium.gif"/$>$ Download high-res image Open in new tab Download Powerpoint Atomic electron tomography (AET) and its transformative impact on the physical sciences.(Top) Schematic diagram of AET, in which 2D images are measured with an advanced electron microscope by tilting a sample to many different orientations. The 3D structure of the sample is iteratively reconstructed from the images, and the coordinates of individual atoms are localized. (Bottom) AET enables 3D imaging of crystal defects\textemdash{}such as grain boundaries, stacking faults, dislocations, and point defects\textemdash{}at atomic resolution. The ability to precisely determine the 3D coordinates of individual atoms allows direct measurements of atomic displacements and the full strain tensor in materials.
Crystallography has been fundamental to the development of many fields of science over the last century. However, much of our modern science and technology relies on materials with defects and disorders, and their three-dimensional (3D) atomic structures are not accessible to crystallography. One method capable of addressing this major challenge is atomic electron tomography. By combining advanced electron microscopes and detectors with powerful data analysis and tomographic reconstruction algorithms, it is now possible to determine the 3D atomic structure of crystal defects such as grain boundaries, stacking faults, dislocations, and point defects, as well as to precisely localize the 3D coordinates of individual atoms in materials without assuming crystallinity. Here we review the recent advances and the interdisciplinary science enabled by this methodology. We also outline further research needed for atomic electron tomography to address long-standing unresolved problems in the physical sciences.},
  language = {en},
  timestamp = {2017-04-13T04:31:41Z},
  number = {6306},
  urldate = {2017-04-13},
  journal = {Science},
  author = {Miao, Jianwei and Ercius, Peter and Billinge, Simon J. L.},
  month = sep,
  year = {2016},
  pages = {aaf2157},
  file = {Snapshot:/Users/sankheshjhaveri/Library/Application Support/Zotero/Profiles/4gdw0u3h.default/zotero/storage/84UMNMSD/aaf2157.html:text/html},
  pmid = {27708010}
}

@inproceedings{oleary_enhancements_2017,
  address = {Los Angeles, CA, USA},
  title = {Enhancements to {{VTK}} Enabling Scientific Visualization in Immersive Environments},
  isbn = {978-1-5090-6647-6},
  doi = {10.1109/VR.2017.7892246},
  abstract = {Modern scientific, engineering and medical computational simulations, as well as experimental and observational data sensing/measuring devices, produce enormous amounts of data. While statistical analysis provides insight into this data, scientific visualization is tactically important for scientific discovery, product design and data analysis. These benefits are impeded, however, when scientific visualization algorithms are implemented from scratch \textemdash{} a time-consuming and redundant process in immersive application development. This process can greatly benefit from leveraging the state-of-the-art open-source Visualization Toolkit (VTK) and its community. Over the past two (almost three) decades, integrating VTK with a virtual reality (VR) environment has only been attempted to varying degrees of success. In this paper, we demonstrate two new approaches to simplify this amalgamation of an immersive interface with visualization rendering from VTK. In addition, we cover several enhancements to VTK that provide near real-time updates and efficient interaction. Finally, we demonstrate the combination of VTK with both Vrui and OpenVR immersive environments in example applications.},
  timestamp = {2017-04-24T15:30:50Z},
  booktitle = {2017 {{IEEE Virtual Reality}} ({{VR}})},
  publisher = {{IEEE}},
  author = {O'Leary, P. and Jhaveri, S. and Chaudhary, A. and Sherman, W. and Martin, K. and Lonie, D. and Whiting, E. and Money, J. and McKenzie, S.},
  month = mar,
  year = {2017},
  keywords = {Context,Data visualization,Geometry,immersive environments,Laboratories,Pipelines,Rendering (computer graphics),Scientific visualization,Software,virtual reality},
  pages = {186--194},
  file = {IEEE Xplore Abstract Record:/Users/sankheshjhaveri/Library/Application Support/Zotero/Profiles/4gdw0u3h.default/zotero/storage/M6EQDQNK/7892246.html:text/html}
}

@article{marchesin_per-pixel_2010,
  title = {Per-{{Pixel Opacity Modulation}} for {{Feature Enhancement}} in {{Volume Rendering}}},
  volume = {16},
  issn = {1077-2626},
  doi = {10.1109/TVCG.2010.30},
  abstract = {Classical direct volume rendering techniques accumulate color and opacity contributions using the standard volume rendering equation approximated by alpha blending. However, such standard rendering techniques, often also aiming at visual realism, are not always adequate for efficient data exploration, especially when large opaque areas are present in a data set, since such areas can occlude important features and make them invisible. On the other hand, the use of highly transparent transfer functions allows viewing all the features at once, but often makes these features barely visible. In order to enhance feature visibility, we present in this paper a straightforward rendering technique that consists of modifying the traditional volume rendering equation. Our approach does not require an opacity transfer function, and instead is based on a function quantifying the relative importance of each voxel in the final rendering called relevance function. This function is subsequently used to dynamically adjust the opacity of the contributions per pixel. We conduct experiments with a number of possible relevance functions in order to show the influence of this parameter. As will be shown by our comparative study, our rendering method is much more suitable than standard volume rendering for interactive data exploration at a low extra cost. Thereby, our method avoids feature visibility restrictions without relying on a transfer function and yet maintains a visual similarity with standard volume rendering.},
  timestamp = {2017-04-28T03:10:15Z},
  number = {4},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  author = {Marchesin, S. and Dischler, J. M. and Mongenet, C.},
  month = jul,
  year = {2010},
  keywords = {adaptive rendering,Algorithms,alpha blending,Computer Graphics,Computer Simulation,feature enhancement,feature extraction,image enhancement,Image Interpretation; Computer-Assisted,Imaging; Three-Dimensional,Models; Theoretical,nonphotorealistic rendering.,opacity,opacity transfer function,per-pixel opacity modulation,relevance function,Rendering (computer graphics),User-Computer Interface,volume rendering,volume rendering equation},
  pages = {560--570},
  file = {IEEE Xplore Abstract Record:/Users/sankheshjhaveri/Library/Application Support/Zotero/Profiles/4gdw0u3h.default/zotero/storage/JBQQZMQG/5406522.html:text/html}
}

@incollection{geveci_vtk_2012,
  edition = {1st},
  title = {{{VTK}}},
  volume = {1},
  isbn = {978-1-257-63801},
  abstract = {The Visualization Toolkit (VTK) is a widely used software system for data processing and visualization. It is used in scientific computing, medical image analysis, computational geometry, rendering, image processing and informatics. In this chapter we provide a brief overview of VTK, including some of the basic design patterns that make it a successful system.},
  language = {en},
  timestamp = {2017-04-28T14:25:52Z},
  booktitle = {The {{Architecture}} of {{Open Source Applications}} - {{Elegance}}, {{Evolution}} and a {{Few Fearless Hacks}}},
  publisher = {{lulu.com}},
  author = {Geveci, Berk and Schroeder, Will},
  editor = {Brown, Amy and Wilson, Greg},
  year = {2012},
  pages = {385 -- 400}
}

@article{blondin_pulsar_2007,
  title = {Pulsar Spins from an Instability in the Accretion Shock of Supernovae},
  volume = {445},
  copyright = {\textcopyright{} 2007 Nature Publishing Group},
  issn = {0028-0836},
  doi = {10.1038/nature05428},
  abstract = {Rotation-powered radio pulsars are born with inferred initial rotation periods of order 300 ms (some as short as 20 ms) in core-collapse supernovae. In the traditional picture, this fast rotation is the result of conservation of angular momentum during the collapse of a rotating stellar core. This leads to the inevitable conclusion that pulsar spin is directly correlated with the rotation of the progenitor star. So far, however, stellar theory has not been able to explain the distribution of pulsar spins, suggesting that the birth rotation is either too slow or too fast. Here we report a robust instability of the stalled accretion shock in core-collapse supernovae that is able to generate a strong rotational flow in the vicinity of the accreting proto-neutron star. Sufficient angular momentum is deposited on the proto-neutron star to generate a final spin period consistent with observations, even beginning with spherically symmetrical initial conditions. This provides a new mechanism for the generation of neutron star spin and weakens, if not breaks, the assumed correlation between the rotational periods of supernova progenitor cores and pulsar spin.},
  language = {en},
  timestamp = {2017-04-28T15:05:41Z},
  number = {7123},
  urldate = {2017-04-28},
  journal = {Nature},
  author = {Blondin, John M. and Mezzacappa, Anthony},
  month = jan,
  year = {2007},
  pages = {58--60},
  file = {Snapshot:/Users/sankheshjhaveri/Library/Application Support/Zotero/Profiles/4gdw0u3h.default/zotero/storage/PZ2UDZS5/nature05428.html:text/html}
}

@article{levin_nanomaterial_2016,
  title = {Nanomaterial Datasets to Advance Tomography in Scanning Transmission Electron Microscopy},
  volume = {3},
  copyright = {\textcopyright{} 2017 Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
  issn = {2052-4463},
  doi = {10.1038/sdata.2016.41},
  abstract = {Electron tomography in materials science has flourished with the demand to characterize nanoscale materials in three dimensions (3D). Access to experimental data is vital for developing and validating reconstruction methods that improve resolution and reduce radiation dose requirements.},
  language = {en},
  timestamp = {2017-04-28T15:11:58Z},
  urldate = {2017-04-28},
  journal = {Scientific Data},
  author = {Levin, Barnaby D. A. and Padgett, Elliot and Chen, Chien-Chun and Scott, M. C. and Xu, Rui and Theis, Wolfgang and Jiang, Yi and Yang, Yongsoo and Ophus, Colin and Zhang, Haitao and Ha, Don-Hyung and Wang, Deli and Yu, Yingchao and Abru{\~n}a, Hector D. and Robinson, Richard D. and Ercius, Peter and Kourkoutis, Lena F. and Miao, Jianwei and Muller, David A. and Hovden, Robert},
  month = jun,
  year = {2016},
  pages = {160041},
  file = {Snapshot:/Users/sankheshjhaveri/Library/Application Support/Zotero/Profiles/4gdw0u3h.default/zotero/storage/S88DVRV7/sdata201641.html:text/html}
}

@book{shreiner_opengl_2013,
  address = {Upper Saddle River, NJ},
  edition = {8th},
  title = {{{OpenGL Programming Guide}}: {{The Official Guide}} to {{Learning OpenGL}}, {{Version}} 4.3},
  isbn = {978-0-321-77303-6},
  shorttitle = {{{OpenGL Programming Guide}}},
  abstract = {Includes Complete Coverage of the OpenGL\textregistered{} Shading Language!   ~  Today's OpenGL software interface enables programmers to produce extraordinarily high-quality computer-generated images and interactive applications using 2D and 3D objects, color images, and programmable shaders.  ~     OpenGL\textregistered{} Programming Guide: The Official Guide to Learning OpenGL\textregistered, Version 4.3, Eighth Edition,   has been almost completely rewritten and provides definitive, comprehensive information on OpenGL and the OpenGL Shading Language. This edition of the best-selling ``Red Book'' describes the features through OpenGL version 4.3. It also includes updated information and techniques formerly covered in OpenGL\textregistered{} Shading Language (the ``Orange Book'').  ~  For the first time, this guide completely integrates shader techniques, alongside classic, functioncentric techniques. Extensive new text and code are presented, demonstrating the latest in OpenGL programming techniques.  ~     OpenGL\textregistered{} Programming Guide, Eighth Edition,   provides clear explanations of OpenGL functionality and techniques, including processing geometric objects with vertex, tessellation, and geometry shaders using geometric transformations and viewing matrices; working with pixels and texture maps through fragment shaders; and advanced data techniques using framebuffer objects and compute shaders.  ~  New OpenGL features covered in this edition include      Best practices and sample code for taking full advantage of shaders and the entire shading pipeline (including geometry and tessellation shaders)     Integration of general computation into the rendering pipeline via compute shaders     Techniques for binding multiple shader programs at once during application execution     Latest GLSL features for doing advanced shading techniques     Additional new techniques for optimizing graphics program performance},
  language = {English},
  timestamp = {2017-04-28T16:13:59Z},
  publisher = {{Addison-Wesley Professional}},
  author = {Shreiner, Dave and Sellers, Graham and Kessenich, John and Licea-Kane, Bill},
  month = mar,
  year = {2013}
}

@book{engel_real-time_2006,
  address = {Wellesley, MA, USA},
  title = {Real-{{Time Volume Graphics}}},
  isbn = {978-1-56881-266-3 978-1-4398-6429-6},
  language = {en},
  timestamp = {2017-05-12T14:27:32Z},
  urldate = {2017-05-12},
  publisher = {{A K Peters/CRC Press}},
  author = {Engel, Klaus and Hadwiger, Markus and Kniss, Joe and Rezk-Salama, Christof and Weiskopf, Daniel},
  month = jul,
  year = {2006},
  doi = {10.1201/b10629}
}

@inproceedings{lorensen_marching_1987,
  address = {New York, NY, USA},
  series = {SIGGRAPH '87},
  title = {Marching {{Cubes}}: {{A High Resolution 3D Surface Construction Algorithm}}},
  isbn = {978-0-89791-227-3},
  shorttitle = {Marching {{Cubes}}},
  doi = {10.1145/37401.37422},
  abstract = {We present a new algorithm, called marching cubes, that creates triangle models of constant density surfaces from 3D medical data. Using a divide-and-conquer approach to generate inter-slice connectivity, we create a case table that defines triangle topology. The algorithm processes the 3D medical data in scan-line order and calculates triangle vertices using linear interpolation. We find the gradient of the original data, normalize it, and use it as a basis for shading the models. The detail in images produced from the generated surface models is the result of maintaining the inter-slice connectivity, surface data, and gradient information present in the original 3D data. Results from computed tomography (CT), magnetic resonance (MR), and single-photon emission computed tomography (SPECT) illustrate the quality and functionality of marching cubes. We also discuss improvements that decrease processing time and add solid modeling capabilities.},
  timestamp = {2017-05-16T18:26:55Z},
  urldate = {2017-05-16},
  booktitle = {Proceedings of the 14th {{Annual Conference}} on {{Computer Graphics}} and {{Interactive Techniques}}},
  publisher = {{ACM}},
  author = {Lorensen, William E. and Cline, Harvey E.},
  year = {1987},
  pages = {163--169}
}

@inproceedings{rezk-salama_interactive_2000,
  address = {New York, NY, USA},
  series = {HWWS '00},
  title = {Interactive {{Volume}} on {{Standard PC Graphics Hardware Using Multi}}-Textures and {{Multi}}-Stage {{Rasterization}}},
  isbn = {978-1-58113-257-1},
  doi = {10.1145/346876.348238},
  abstract = {Interactive direct volume rendering has yet been restricted to high-end graphics workstations and special-purpose hardware, due to the large amount of trilinear interpolations, that are necessary to obtain high image quality. Implementations that use the 2D-texture capabilities of standard PC hardware, usually render object-aligned slices in order to substitute trilinear by bilinear interpolation. However the resulting images often contain visual artifacts caused by the lack of spatial interpolation. In this paper we propose new rendering techniques that significantly improve both performance and image quality of the 2D-texture based approach. We will show how in ulti-texturing capabilitiesof modern consumer PC graphboards are exploited to enable in teractive high quality volume visualization on low-cost hardware. Furthermore we demonstrate how multi-stage rasterization hardware can be used to efficiently render shaded isosurfaces and to compute diffuse illumination for semi-transparent volume rendering at interactive frame rates.},
  timestamp = {2017-05-16T18:32:27Z},
  urldate = {2017-05-16},
  booktitle = {Proceedings of the {{ACM SIGGRAPH}}/{{EUROGRAPHICS Workshop}} on {{Graphics Hardware}}},
  publisher = {{ACM}},
  author = {Rezk-Salama, C. and Engel, K. and Bauer, M. and Greiner, G. and Ertl, T.},
  year = {2000},
  keywords = {multi-textures,PC hardware,rasterization,volume rendering},
  pages = {109--118}
}

@inproceedings{yagel_accelerating_1993,
  address = {Washington, DC, USA},
  series = {VIS '93},
  title = {Accelerating {{Volume Animation}} by {{Space}}-Leaping},
  isbn = {978-0-8186-3940-1},
  abstract = {In this paper we present a method for speeding the process of volume animation. It exploits coherency between consecutive images to shorten the path rays take through the volume. Rays are provided with the information needed to leap over the empty space and commence volume traversal at the vicinity of meaningful data. The algorithm starts by projecting the volume onto a C-buffer (Coordinates-buffer) which stores the object-space coordinates of the first non-empty voxel visible from a pixel. Following a change in the viewing parameters, the C-buffer is transformed accordingly. Next, coordinates that possibly became hidden are discarded. The remaining values serve as an estimate of the point where the new rays should start their volume traversal. This method does not require 3D preprocessing and does not suffer from any image degradation. It can be combined with existing acceleration techniques and can support any ray traversal algorithm and material modeling scheme.},
  timestamp = {2017-05-16T18:33:03Z},
  urldate = {2017-05-16},
  booktitle = {Proceedings of the 4th {{Conference}} on {{Visualization}} '93},
  publisher = {{IEEE Computer Society}},
  author = {Yagel, Roni and Shi, Zhouhong},
  year = {1993},
  pages = {62--69}
}

@inproceedings{engel_high-quality_2001,
  address = {New York, NY, USA},
  series = {HWWS '01},
  title = {High-Quality {{Pre}}-Integrated {{Volume Rendering Using Hardware}}-Accelerated {{Pixel Shading}}},
  isbn = {978-1-58113-407-0},
  doi = {10.1145/383507.383515},
  abstract = {We introduce a novel texture-based volume rendering approach that achieves the image quality of the best post-shading approaches with far less slices. It is suitable for new flexible consumer graphics hardware and provides high image quality even for low-resolution volume data and non-linear transfer functions with high frequencies, without the performance overhead caused by rendering additional interpolated slices. This is especially useful for volumetric effects in computer games and professional scientific volume visualization, which heavily depend on memory bandwidth and rasterization power.
We present an implementation of the algorithm on current programmable consumer graphics hardware using multi-textures with advanced texture fetch and pixel shading operations. We implemented direct volume rendering, volume shading, arbitrary number of isosurfaces, and mixed mode rendering. The performance does neither depend on the number of isosurfaces nor the definition of the transfer functions, and is therefore suited for interactive high-quality volume graphics.},
  timestamp = {2017-05-16T18:33:34Z},
  urldate = {2017-05-16},
  booktitle = {Proceedings of the {{ACM SIGGRAPH}}/{{EUROGRAPHICS Workshop}} on {{Graphics Hardware}}},
  publisher = {{ACM}},
  author = {Engel, Klaus and Kraus, Martin and Ertl, Thomas},
  year = {2001},
  keywords = {direct volume rendering,flexible graphics hardware,multi-textures,PC graphics hardware,rasterization,volume graphics,volume shading,volume visualization},
  pages = {9--16}
}

@inproceedings{westover_footprint_1990,
  address = {New York, NY, USA},
  series = {SIGGRAPH '90},
  title = {Footprint {{Evaluation}} for {{Volume Rendering}}},
  isbn = {978-0-89791-344-7},
  doi = {10.1145/97879.97919},
  abstract = {This paper presents a forward mapping rendering algorithm to display regular volumetric grids that may not have the same spacings in the three grid directions. It takes advantage of the fact that convolution can be thought of as distributing energy from input samples into space. The renderer calculates an image plane footprint for each data sample and uses the footprint to spread the sample's energy onto the image plane. A result of the technique is that the forward mapping algorithm can support perspective without excessive cost, and support adaptive resampling of the three-dimensional data set during image generation.},
  timestamp = {2017-05-16T18:34:09Z},
  urldate = {2017-05-16},
  booktitle = {Proceedings of the 17th {{Annual Conference}} on {{Computer Graphics}} and {{Interactive Techniques}}},
  publisher = {{ACM}},
  author = {Westover, Lee},
  year = {1990},
  pages = {367--376}
}

@inproceedings{hsu_segmented_1993,
  address = {New York, NY, USA},
  series = {PRS '93},
  title = {Segmented {{Ray Casting}} for {{Data Parallel Volume Rendering}}},
  isbn = {978-0-89791-618-9},
  doi = {10.1145/166181.166182},
  timestamp = {2017-05-16T18:34:36Z},
  urldate = {2017-05-16},
  booktitle = {Proceedings of the 1993 {{Symposium}} on {{Parallel Rendering}}},
  publisher = {{ACM}},
  author = {Hsu, William M.},
  year = {1993},
  keywords = {rendering,volume},
  pages = {7--14}
}

@inproceedings{ma_parallel_1995,
  address = {New York, NY, USA},
  series = {PRS '95},
  title = {Parallel {{Volume Ray}}-Casting for {{Unstructured}}-Grid {{Data}} on {{Distributed}}-Memory {{Architectures}}},
  isbn = {978-0-89791-774-2},
  doi = {10.1145/218327.218333},
  timestamp = {2017-05-16T18:35:06Z},
  urldate = {2017-05-16},
  booktitle = {Proceedings of the {{IEEE Symposium}} on {{Parallel Rendering}}},
  publisher = {{ACM}},
  author = {Ma, Kwan-Liu},
  year = {1995},
  pages = {23--30}
}

@inproceedings{ma_scalable_1997,
  address = {New York, NY, USA},
  series = {PRS '97},
  title = {A {{Scalable Parallel Cell}}-Projection {{Volume Rendering Algorithm}} for {{Three}}-Dimensional {{Unstructured Data}}},
  isbn = {978-1-58113-010-2},
  doi = {10.1145/266638.266664},
  timestamp = {2017-05-16T18:37:25Z},
  urldate = {2017-05-16},
  booktitle = {Proceedings of the {{IEEE Symposium}} on {{Parallel Rendering}}},
  publisher = {{ACM}},
  author = {Ma, Kwan-Liu and Crockett, Thomas W.},
  year = {1997},
  keywords = {asynchronous communication,distributed memory,hierarchical data structures,load balancing,message passing,parallel algorithms,Scientific visualization,unstructured grids,volume rendering},
  pages = {95--ff.}
}

@inproceedings{heng_gpu-based_2005,
  title = {{{GPU}}-Based {{Volume Rendering}} for {{Medical Image Visualization}}},
  doi = {10.1109/IEMBS.2005.1615635},
  abstract = {During the quick advancements of medical image visualization and augmented virtual reality application, the low performance of the volume rendering algorithm is still a "bottle neck". To facilitate the usage of well developed hardware resource, a novel graphics processing unit (GPU)-based volume ray-casting algorithm is proposed in this paper. Running on a normal PC, it performs an interactive rate while keeping the same image quality as the traditional volume rendering algorithm does. Recently, GPU-accelerated direct volume rendering has positioned itself as an efficient tool for the display and visual analysis of volume data. However, for large sized medical image data, it often shows low efficiency for too large memories requested. Furthermore, it always holds a drawback of writing color buffers multi-times per frame. The proposed algorithm improves the situation by implementing ray casting operation completely in GPU. It needs only one slice plane from CPU and one 3Dtexture to store data when GPU calculates the two terminals of the ray and carries out the color blending operation in its pixel programs. So both the rendering speed and the memories consumed are improved, and the algorithm can deal most medical image data on normal PCs in the interactive speed},
  timestamp = {2017-05-16T18:51:21Z},
  booktitle = {2005 {{IEEE Engineering}} in {{Medicine}} and {{Biology}} 27th {{Annual Conference}}},
  author = {Heng, Yang and Gu, Lixu},
  month = jan,
  year = {2005},
  keywords = {3Dtexture,augmented virtual reality application,Biomedical imaging,color blending operation,computerised tomography,Data analysis,direct volume rendering,Displays,GPU acceleration,GPU-based volume rendering,Graphics,graphics processing unit,Hardware,image colour analysis,Image quality,image texture,medical image data,medical image processing,medical image visualization,Neck,Rendering (computer graphics),virtual reality,Visualization,volume ray-casting algorithm},
  pages = {5145--5148},
  file = {IEEE Xplore Abstract Record:/Users/sankheshjhaveri/Library/Application Support/Zotero/Profiles/4gdw0u3h.default/zotero/storage/8FFV7G5D/1615635.html:text/html}
}

@article{meyer-spradow_voreen:_2009,
  title = {Voreen: {{A Rapid}}-{{Prototyping Environment}} for {{Ray}}-{{Casting}}-{{Based Volume Visualizations}}},
  volume = {29},
  issn = {0272-1716},
  shorttitle = {Voreen},
  doi = {10.1109/MCG.2009.130},
  abstract = {By splitting a complex ray-casting process into different tasks performed on different processors, Voreen provides a lot of flexibility because users can intervene at different points during ray casting. Voreen's object-oriented design lets users easily create customized processor classes that cooperate seamlessly with existing classes. A user-friendly GUI supports rapid prototyping of visualization ideas. We've implemented several applications based on our library. In the future, we'd like to further extend Voreen's capabilities to make visualization prototyping even easier on all abstraction levels. Thus, we plan to realize a set of dedicated processor skeletons, which are solely configured through shader programs and can thus be modified at runtime.},
  timestamp = {2017-05-16T18:43:05Z},
  number = {6},
  journal = {IEEE Computer Graphics and Applications},
  author = {Meyer-Spradow, J. and Ropinski, T. and Mensmann, J. and Hinrichs, K.},
  month = nov,
  year = {2009},
  keywords = {0,Casting,GPU-based ray casting,graphical user interfaces,GUI,Libraries,object-oriented design,object-oriented methods,program visualisation,Prototypes,rapid-prototyping environment,ray-casting-based volume visualizations,Runtime,Skeleton,software prototyping,Visualization,visualization prototyping,volume rendering,Voreen},
  pages = {6--13},
  file = {IEEE Xplore Abstract Record:/Users/sankheshjhaveri/Library/Application Support/Zotero/Profiles/4gdw0u3h.default/zotero/storage/MKKBFFF7/5307637.html:text/html}
}

@article{wallis_three-dimensional_1989,
  title = {Three-Dimensional Display in Nuclear Medicine},
  volume = {8},
  issn = {0278-0062},
  doi = {10.1109/42.41482},
  abstract = {Several surface and volume rendering techniques are compared using nuclear medicine data including several new methods developed by the authors specifically for scintigraphic data. The techniques examined are summed projection, thresholded projection, threshold-based surface illumination, volumetric compositing, maximum-activity projection, sun-weighted maximum-activity projection, and variable attenuation. The advantages and disadvantages of each method are discussed in relation to the goals of three-dimensional display, which are defined herein. Selected images are shown to illustrate the usefulness of the methods.},
  language = {eng},
  timestamp = {2017-05-16T18:44:34Z},
  number = {4},
  journal = {IEEE transactions on medical imaging},
  author = {Wallis, J. W. and Miller, T. R. and Lerner, C. A. and Kleerup, E. C.},
  year = {1989},
  pages = {297--230},
  pmid = {18230529}
}

@article{clendenon_voxx:_2002,
  title = {Voxx: A {{PC}}-Based, near Real-Time Volume Rendering System for Biological Microscopy},
  volume = {282},
  issn = {0363-6143},
  shorttitle = {Voxx},
  abstract = {Confocal and two-photon fluorescence microscopy have advanced the exploration of complex, three-dimensional biological structures at submicron resolution. We have developed a voxel-based three-dimensional (3-D) imaging program (Voxx) capable of near real-time rendering that runs on inexpensive personal computers. This low-cost interactive 3-D imaging system provides a powerful tool for analyzing complex structures in cells and tissues and encourages a more thorough exploration of complex biological image data.},
  language = {eng},
  timestamp = {2017-05-16T20:28:31Z},
  number = {1},
  journal = {American Journal of Physiology. Cell Physiology},
  author = {Clendenon, Jeffrey L. and Phillips, Carrie L. and Sandoval, Ruben M. and Fang, Shiaofen and Dunn, Kenneth W.},
  month = jan,
  year = {2002},
  keywords = {Animals,Cell Line,Computer Systems,Image Processing; Computer-Assisted,Kidney,Mice,Microscopy; Confocal,Myocardium,Rats,Software,Swine},
  pages = {C213--218},
  pmid = {11742814}
}

@article{royer_clearvolume:_2015,
  title = {{{ClearVolume}}: Open-Source Live {{3D}} Visualization for Light-Sheet Microscopy},
  volume = {12},
  copyright = {\textcopyright{} 2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  issn = {1548-7091},
  shorttitle = {{{ClearVolume}}},
  doi = {10.1038/nmeth.3372},
  abstract = {To the Editor:
Current state-of-the-art light-sheet microscopes rely on sophisticated control software to perform the acquisition of gigabytes of image data per second over the course of hours or even days. Typically the microscopes acquire data in a first step, and in a second step these data are processed and visualized\ldots{}},
  language = {en},
  timestamp = {2017-05-16T20:29:37Z},
  number = {6},
  urldate = {2017-05-16},
  journal = {Nature Methods},
  author = {Royer, Loic A. and Weigert, Martin and G{\"u}nther, Ulrik and Maghelli, Nicola and Jug, Florian and Sbalzarini, Ivo F. and Myers, Eugene W.},
  month = jun,
  year = {2015},
  keywords = {Light-sheet microscopy,Software,Systems biology},
  pages = {480--481},
  file = {Snapshot:/Users/sankheshjhaveri/Library/Application Support/Zotero/Profiles/4gdw0u3h.default/zotero/storage/KCST8EV3/nmeth.3372.html:text/html}
}

@misc{schrodinger_llc_pymol_2015,
  title = {The {{PyMOL Molecular Graphics System}}, {{Version}} 1.8},
  timestamp = {2017-05-16T20:49:26Z},
  howpublished = {\url{https://www.pymol.org/}},
  journal = {PyMOL  The PyMOL Molecular Graphics System, Version 1.8, Schr{\"o}dinger, LLC.},
  author = {{Schr{\"o}dinger, LLC}},
  month = nov,
  year = {2015}
}

@article{wald_ospray_2017,
  title = {{{OSPRay}} - {{A CPU Ray Tracing Framework}} for {{Scientific Visualization}}},
  volume = {23},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2016.2599041},
  abstract = {Scientific data is continually increasing in complexity, variety and size, making efficient visualization and specifically rendering an ongoing challenge. Traditional rasterization-based visualization approaches encounter performance and quality limitations, particularly in HPC environments without dedicated rendering hardware. In this paper, we present OSPRay, a turn-key CPU ray tracing framework oriented towards production-use scientific visualization which can utilize varying SIMD widths and multiple device backends found across diverse HPC resources. This framework provides a high-quality, efficient CPU-based solution for typical visualization workloads, which has already been integrated into several prevalent visualization packages. We show that this system delivers the performance, high-level API simplicity, and modular device support needed to provide a compelling new rendering framework for implementing efficient scientific visualization workflows.},
  language = {eng},
  timestamp = {2017-05-16T20:39:43Z},
  number = {1},
  journal = {IEEE transactions on visualization and computer graphics},
  author = {Wald, I. and Johnson, G. P. and Amstutz, J. and Brownlee, C. and Knoll, A. and Jeffers, J. and Gunther, J. and Navratil, P.},
  month = jan,
  year = {2017},
  pages = {931--940},
  pmid = {27875206}
}

@inproceedings{parker_optix:_2010,
  address = {New York, NY, USA},
  series = {SIGGRAPH '10},
  title = {{{OptiX}}: {{A General Purpose Ray Tracing Engine}}},
  isbn = {978-1-4503-0210-4},
  shorttitle = {{{OptiX}}},
  doi = {10.1145/1833349.1778803},
  abstract = {The NVIDIA\textregistered{} OptiX\texttrademark{} ray tracing engine is a programmable system designed for NVIDIA GPUs and other highly parallel architectures. The OptiX engine builds on the key observation that most ray tracing algorithms can be implemented using a small set of programmable operations. Consequently, the core of OptiX is a domain-specific just-in-time compiler that generates custom ray tracing kernels by combining user-supplied programs for ray generation, material shading, object intersection, and scene traversal. This enables the implementation of a highly diverse set of ray tracing-based algorithms and applications, including interactive rendering, offline rendering, collision detection systems, artificial intelligence queries, and scientific simulations such as sound propagation. OptiX achieves high performance through a compact object model and application of several ray tracing-specific compiler optimizations. For ease of use it exposes a single-ray programming model with full support for recursion and a dynamic dispatch mechanism similar to virtual function calls.},
  timestamp = {2017-05-16T20:40:26Z},
  urldate = {2017-05-16},
  booktitle = {{{ACM SIGGRAPH}} 2010 {{Papers}}},
  publisher = {{ACM}},
  author = {Parker, Steven G. and Bigler, James and Dietrich, Andreas and Friedrich, Heiko and Hoberock, Jared and Luebke, David and McAllister, David and McGuire, Morgan and Morley, Keith and Robison, Austin and Stich, Martin},
  year = {2010},
  keywords = {graphics hardware,graphics systems,ray tracing},
  pages = {66:1--66:13}
}

@misc{cibc_imagevis3d:_2016,
  title = {{{ImageVis3D}}: {{An}} Interactive Visualization Software System for Large-Scale Volume Data. {{The NIH}}/{{NIGMS Center}} for {{Integrative Biomedical Computing}}.},
  timestamp = {2017-05-17T02:14:15Z},
  howpublished = {\url{http://www.imagevis3d.org}},
  author = {{CIBC}},
  year = {2016}
}

@article{pfister_transfer_2001,
  title = {The Transfer Function Bake-Off},
  volume = {21},
  issn = {0272-1716},
  doi = {10.1109/38.920623},
  abstract = {Direct volume rendering is a key technology for visualizing large 3D data sets from scientific or medical applications. Transfer functions are particularly important to the quality of direct volume-rendered images. A transfer function assigns optical properties, such as color and opacity, to original values of the data set being visualized. Unfortunately, finding good transfer functions proves difficult. It is one of the major problems in volume visualization. The article examines four of the currently most promising approaches to transfer function design. The four approaches are: trial and error, with minimum computer aid; data-centric, with no underlying assumed model; data-centric, using an underlying data model; and image-centric, using organized sampling},
  timestamp = {2017-06-20T03:29:24Z},
  number = {3},
  journal = {IEEE Computer Graphics and Applications},
  author = {Pfister, H. and Lorensen, B. and Bajaj, C. and Kindlmann, G. and Schroeder, W. and Avila, L. S. and Raghu, K. M. and Machiraju, R. and Lee, Jinho},
  month = may,
  year = {2001},
  keywords = {color,Computer errors,data-centric,data visualisation,Data visualization,direct volume-rendered images,direct volume rendering,Heart,image-centric,Image generation,Isosurfaces,Knee,large 3D data set visualization,Magnetic resonance imaging,opacity,optical properties,organized sampling,Rendering (computer graphics),Teeth,transfer function,Transfer functions,trial and error,underlying data model,volume visualization},
  pages = {16--22},
  file = {IEEE Xplore Abstract Record:/Users/sankheshjhaveri/Library/Application Support/Zotero/Profiles/4gdw0u3h.default/zotero/storage/VVGKRMC6/Pfister et al. - 2001 - The transfer function bake-off.html:text/html}
}

@article{fedorov_3d_2012,
  series = {Quantitative Imaging in Cancer},
  title = {{{3D Slicer}} as an Image Computing Platform for the {{Quantitative Imaging Network}}},
  volume = {30},
  issn = {0730-725X},
  doi = {10.1016/j.mri.2012.05.001},
  abstract = {Quantitative analysis has tremendous but mostly unrealized potential in healthcare to support objective and accurate interpretation of the clinical imaging. In 2008, the National Cancer Institute began building the Quantitative Imaging Network (QIN) initiative with the goal of advancing quantitative imaging in the context of personalized therapy and evaluation of treatment response. Computerized analysis is an important component contributing to reproducibility and efficiency of the quantitative imaging techniques. The success of quantitative imaging is contingent on robust analysis methods and software tools to bring these methods from bench to bedside. 3D Slicer is a free open-source software application for medical image computing. As a clinical research tool, 3D Slicer is similar to a radiology workstation that supports versatile visualizations but also provides advanced functionality such as automated segmentation and registration for a variety of application domains. Unlike a typical radiology workstation, 3D Slicer is free and is not tied to specific hardware. As a programming platform, 3D Slicer facilitates translation and evaluation of the new quantitative methods by allowing the biomedical researcher to focus on the implementation of the algorithm and providing abstractions for the common tasks of data communication, visualization and user interface development. Compared to other tools that provide aspects of this functionality, 3D Slicer is fully open source and can be readily extended and redistributed. In addition, 3D Slicer is designed to facilitate the development of new functionality in the form of 3D Slicer extensions. In this paper, we present an overview of 3D Slicer as a platform for prototyping, development and evaluation of image analysis tools for clinical research applications. To illustrate the utility of the platform in the scope of QIN, we discuss several use cases of 3D Slicer by the existing QIN teams, and we elaborate on the future directions that can further facilitate development and validation of imaging biomarkers using 3D Slicer.},
  timestamp = {2017-06-20T03:32:52Z},
  number = {9},
  urldate = {2017-06-20},
  journal = {Magnetic Resonance Imaging},
  author = {Fedorov, Andriy and Beichel, Reinhard and Kalpathy-Cramer, Jayashree and Finet, Julien and Fillion-Robin, Jean-Christophe and Pujol, Sonia and Bauer, Christian and Jennings, Dominique and Fennessy, Fiona and Sonka, Milan and Buatti, John and Aylward, Stephen and Miller, James V. and Pieper, Steve and Kikinis, Ron},
  month = nov,
  year = {2012},
  keywords = {Brain,Cancer imaging,Cancer treatment response,CT,Glioblastima,Head and neck,Image analysis,Imaging biomarkers,Medical imaging,MRI,PET,Prostate,Quantitative imaging,Software tools},
  pages = {1323--1341},
  file = {ScienceDirect Snapshot:/Users/sankheshjhaveri/Library/Application Support/Zotero/Profiles/4gdw0u3h.default/zotero/storage/EK53796T/S0730725X12001816.html:text/html}
}


